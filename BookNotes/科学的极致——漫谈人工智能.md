# 科学的极致——漫谈人工智能

人的智能涉及模式识别、分类、学习、记忆、归纳、类比、泛化、联想、规划、优化、创新、演绎推理、问题求解、语言处理、生存、繁衍等方面。
胡特的通用智能模型 AXI 的核心是索洛莫诺夫的通用归纳模型。事实上，将索洛莫诺夫的通用归纳与序贯决策理论相结合就得到了通用智能模型 AIXI。序贯决策理论研究的是在客观概率分布已知但具体状态不确定的动态环境中，主体如何寻求最大化期望效用。它从初始状态开始，每个时刻根据所观察到的状态和以前状态的记录，依照已知的概率分布，从一组可行的方案中选用一个能够获得最大化期望效用的最优方案，接着观察下一步实际出现的状态。 
科学是压缩的艺术，简单性是科学的基本假设，探索世界背后的运行模式就是在寻找简单的算法。有了算法概率做武器，再借助序贯决策理论帮助我们追逐效用，能够自动适应各种可能环境的超级智能体 AIXI 就诞生了。
简言之，通用智能的核心是通用归纳。通用归纳将归纳转化为预测，而预测的关键是压缩。压缩可以理解为对数据的建模或编码表示，它依赖于对模式的掌握，模式可以用算法来衡量。

### 第五章
科学是对经验的理解，理解就是压缩，预测可以看作某种解压缩

人脑和世界可计算的猜想越来越受重视，很大程度上源于图灵论题牢不可破的信念。

智能是主体在各种各样的纷繁复杂的环境中实现目标的能力。——肖恩·莱格，马库斯·胡特

![](https://img3.doubanio.com/view/page_note/large/public/p38923848-3.jpg)

![](https://img3.doubanio.com/view/page_note/large/public/p38923848-2.jpg)


哥德尔机包含两个并行运行的部分：Solver 和 Searcher：Solver 负责与环境交互，尽可能最大化期望积累效用；Searcher 内嵌了一个形式系统，形式系统里有对 Solver、Searcher、效用函数的完全描述以及对环境的部分描述，Searcher 可以对哥德尔机各部分的源代码进行彻底的修改，条件是它内嵌的形式系统的定理证明器能证明“修改后的主体在未来的时间里将获得比现在更大的期望累积效用”。

强大的智能体必然复杂，复杂且强大的智能体是存在的，但只要它足够复杂，形式系统将无法帮助我们找到它。

### 第六章 深度学习：大数据时代的人工智能新途径

深层神经网络 Deep Naural Networks （DNN）

机器学习是通过算法，使得机器能从大量历史数据中学习规律，从而对新的样本做智能识别或对未来做预测。机器学习发展大致经历了两次浪潮：浅层学习（shallow learning）和深度学习（deep learning）。

第一个神经元模型是麦卡洛克和匹兹在1943年提出的，称为 threshold logic，自此以后，神经网络的研究分化为两个方向：专注于生物信息处理的生物神经网络，和专注于工程应用的人工神经网络。

2006年，辛顿提出深度网络（深层次的神经网络）和深度学习概念。

用机器学习特定问题时，一般采集到数据之后会进行一些特征提取的处理，再把提取出的特征丢到各种机器学习模型（如 SVM 支持向量机）里做分类或预测。

传统的浅层模型有一个重要特点，就是靠人工经验来抽取样本的特征，而强调模型主要负责分类或预测。**深度学习的实质，是通过构建具有很多隐层的机器学习模型和海量的训练数据，来学习更有用的特征，从而最终提升分类或预测的准确性。**与浅层学习的不同：

- 强调模型结构的深度，通常有5、6层，甚至10多层的隐层节点
- 明确突出表示学习的重要性，通过逐层特征变换，将样本在原空间的特征表示变换到一个新特征空间，使分类或预测更加容易。

深度学习的基本模块：自编码器，受限玻尔茨曼机（RBM）

RBM 是可以在输入数据集上学习概率分布的生成随机神经网络，由隐含层、可见层、偏置层组成。



